{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anaferreira744/DE-DP-ADF/blob/main/spark_streaming/examples/example_3_api_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_GBE9UsyxwK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "592b80fa-191c-4c3d-ab44-f30af97f73b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "637HFw00T3LP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master('local').appName('Test streaming').getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/landing\n",
        "!rm -rf /content/bronze\n",
        "!mkdir -p /content/landing"
      ],
      "metadata": {
        "id": "aF7fzyYIJi0l"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulate producer:\n",
        "- extract data from API\n",
        "- store data as json in the lake\n",
        "- run task async"
      ],
      "metadata": {
        "id": "RZdHGoFyTlMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pyspark.sql.types import *\n",
        "import json\n",
        "import datetime\n",
        "import asyncio\n",
        "\n",
        "\n",
        "async def ingest_from_api(url: str, table: str, schema: StructType = None):\n",
        "  response = requests.get(url)\n",
        "  timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") #quero adicionar o timestamp no nome do file\n",
        "  if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    with open(f\"/content/landing/{table}_{int(timestamp)}.json\", \"w\") as f: #como o open é python entao temos de criar o dir primeiro.se fosse spark criava logo\n",
        "        json.dump(data, f)\n",
        "\n",
        "#outro método\n",
        "async def producer(loop: int, interval_time: int): #interval time o tempo que eu quero esperar entre o loop\n",
        "  for i in range(loop):\n",
        "    await ingest_from_api(\"https://api.carrismetropolitana.pt/vehicles\", \"vehicles\")\n",
        "    await ingest_from_api(\"https://api.carrismetropolitana.pt/lines\", \"lines\")\n",
        "    await asyncio.sleep(interval_time)\n",
        "\n",
        "async def main():\n",
        "  asyncio.create_task(producer(10, 30)) #iterar 10 vezes, 30 segundos de intervalo\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "tTQhp8UbFUCl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Read from /content/landing as streaming\n",
        "- store data in memory (for testing)\n",
        "- store data in the bronze layer"
      ],
      "metadata": {
        "id": "kIqHdZEKUEmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/landing | wc"
      ],
      "metadata": {
        "id": "yoxQfgMpd1VH",
        "outputId": "97a7974d-547d-43cd-dfde-2163292cc52a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     20      20     550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "vehicle_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                             StructField('block_id', StringType(), True),\n",
        "                             StructField('current_status', StringType(), True),\n",
        "                             StructField('id', StringType(), True),\n",
        "                             StructField('lat', FloatType(), True),\n",
        "                             StructField('line_id', StringType(), True),\n",
        "                             StructField('lon', FloatType(), True),\n",
        "                             StructField('pattern_id', StringType(), True),\n",
        "                             StructField('route_id', StringType(), True),\n",
        "                             StructField('schedule_relationship', StringType(), True),\n",
        "                             StructField('shift_id', StringType(), True),\n",
        "                             StructField('speed', FloatType(), True),\n",
        "                             StructField('stop_id', StringType(), True),\n",
        "                             StructField('timestamp', TimestampType(), True),\n",
        "                             StructField('trip_id', StringType(), True)])\n",
        "\n",
        "stream = spark.readStream.format(\"json\").schema(vehicle_schema).load(\"/content/landing/vehicles*\")\n",
        "\n",
        "dedup = stream.dropDuplicates()"
      ],
      "metadata": {
        "id": "_dTSf527Fhy0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dedup.printSchema()"
      ],
      "metadata": {
        "id": "4k1Em4igeimj",
        "outputId": "0af09a7f-156e-48b8-f5b2-a30cb77491c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- bearing: integer (nullable = true)\n",
            " |-- block_id: string (nullable = true)\n",
            " |-- current_status: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- lat: float (nullable = true)\n",
            " |-- line_id: string (nullable = true)\n",
            " |-- lon: float (nullable = true)\n",
            " |-- pattern_id: string (nullable = true)\n",
            " |-- route_id: string (nullable = true)\n",
            " |-- schedule_relationship: string (nullable = true)\n",
            " |-- shift_id: string (nullable = true)\n",
            " |-- speed: float (nullable = true)\n",
            " |-- stop_id: string (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- trip_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using memory for testing\n",
        "try:\n",
        "  if query.isActive:\n",
        "    query.stop()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "query = (dedup.writeStream.format(\"memory\").option(\"queryName\", \"vehicles\").start())"
      ],
      "metadata": {
        "id": "9N99eI41UUFA"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query.status"
      ],
      "metadata": {
        "id": "tmEpnIQIglzk",
        "outputId": "62d1c4cc-e65f-4b89-fc2f-f669d2ee2034",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'Processing new data',\n",
              " 'isDataAvailable': True,\n",
              " 'isTriggerActive': True}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from vehicles\").show()"
      ],
      "metadata": {
        "id": "wT9pNrwoXBi4",
        "outputId": "f0476998-c038-4271-ce1f-ce824a3f42b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+\n",
            "|bearing|            block_id|current_status|      id|      lat|line_id|      lon|pattern_id|route_id|schedule_relationship|    shift_id|    speed|stop_id|          timestamp|             trip_id|\n",
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+\n",
            "|    170|           2_2752-21| IN_TRANSIT_TO|  41|814|38.805965|   1205|-9.329573|  1205_0_1|  1205_0|            SCHEDULED|        2752| 9.444445| 170249|2024-11-30 10:35:46|1205_0_1_1000_102...|\n",
            "|    233|20241130-64020021...| IN_TRANSIT_TO|44|12550| 38.52468|   4562|-8.998977|  4562_0_1|  4562_0|            SCHEDULED|111030000007|      7.5| 160897|2024-11-30 10:35:47|4562_0_1|3000|094...|\n",
            "|      0|      ESC_SAB_ES3015|    STOPPED_AT| 43|2101| 38.56613|   3635|-9.036482|  3635_0_1|  3635_0|            SCHEDULED|      ES3015|      0.0| 150003|2024-11-30 10:35:50|3635_0_1_1030_105...|\n",
            "|    125|           2_2716-21| IN_TRANSIT_TO| 41|1900| 38.79841|   1205|-9.350028|  1205_0_2|  1205_0|            SCHEDULED|        2716|11.111111| 170197|2024-11-30 10:35:24|1205_0_2_0930_095...|\n",
            "|    337|             4504-21| IN_TRANSIT_TO| 42|2532|  38.7667|   2702|-9.157731|  2702_0_1|  2702_0|            SCHEDULED|        4536|     10.0| 060159|2024-11-30 10:34:37|2702_0_1|2|1|1030...|\n",
            "|      0|      ESC_SAB_ES3001|    STOPPED_AT| 43|2612|38.568623|   3620|-9.046746|  3620_0_1|  3620_0|            SCHEDULED|      ES3001|      0.0| 150021|2024-11-30 10:35:32|3620_0_1_1000_102...|\n",
            "|    287|      ESC_SAB_ES1057| IN_TRANSIT_TO| 43|2210|38.668175|   3717|-9.165437|  3717_0_2|  3717_0|            SCHEDULED|      ES1059|      0.0| 020003|2024-11-30 10:34:47|3717_0_2_1000_102...|\n",
            "|     62|           2_2904-21| IN_TRANSIT_TO| 41|1265|38.833954|   1255|-9.319593|  1255_0_2|  1255_0|            SCHEDULED|        2904|     12.5| 171982|2024-11-30 10:34:23|1255_0_2_1000_102...|\n",
            "|    351|             4042-21|    STOPPED_AT| 42|2362|38.814564|   2710|-9.118222|  2710_0_2|  2710_0|            SCHEDULED|        4146|      0.0| 070129|2024-11-30 10:33:55|2710_0_2|2|1|1000...|\n",
            "|      0|      ESC_SAB_ES1048|    STOPPED_AT| 43|2331|38.601173|   3521|-9.139042|  3521_0_2|  3521_0|            SCHEDULED|      ES1048|      0.0| 140187|2024-11-30 10:33:57|3521_0_2_1000_102...|\n",
            "|    223|      ESC_SAB_ES1038|   INCOMING_AT| 43|2329|38.624714|   3112|-9.085278|  3112_0_2|  3112_0|            SCHEDULED|      ES1038|6.9444447| 140331|2024-11-30 10:34:12|3112_0_2_1000_102...|\n",
            "|     79|20241130-64020039...| IN_TRANSIT_TO|44|12063| 38.52549|   4412|-8.893345|  4412_0_2|  4412_0|            SCHEDULED|112100000007| 8.333333| 160137|2024-11-30 10:34:53|4412_0_2|3000|103...|\n",
            "|    283|           2_2306-21|   INCOMING_AT| 41|1212| 38.80189|   1614|-9.373151|  1614_0_1|  1614_0|            SCHEDULED|        2321|10.833333| 170819|2024-11-30 10:35:49|1614_0_1_0930_095...|\n",
            "|     51|      ESC_SAB_ES2011| IN_TRANSIT_TO| 43|2241| 38.67648|   3022|-9.164474|  3022_0_1|  3022_0|            SCHEDULED|      ES2011|4.4444447| 020083|2024-11-30 10:35:34|3022_0_1_1000_102...|\n",
            "|     60|           2_2412-21|    STOPPED_AT| 41|1290| 38.71459|   1606|-9.256597|  1606_0_2|  1606_0|            SCHEDULED|        2412|0.2777778| 120292|2024-11-30 10:35:51|1606_0_2_1000_102...|\n",
            "|    157|      ESC_SAB_ES2014| IN_TRANSIT_TO| 43|2306| 38.61498|   3030|-9.190934|  3030_0_2|  3030_0|            SCHEDULED|      ES2014|6.9444447| 020342|2024-11-30 10:35:24|3030_0_2_0930_095...|\n",
            "|      0|             4036-21|    STOPPED_AT| 42|2338|38.759167|   2736|-9.159937|  2736_0_3|  2736_0|            SCHEDULED|        4036|      0.0| 060259|2024-11-30 10:35:28|2736_0_3|2|1|1040...|\n",
            "|    278|           2_2318-21|    STOPPED_AT| 41|1243|38.788998|   1209|-9.306471|  1209_0_2|  1209_0|            SCHEDULED|        2318|0.2777778| 170486|2024-11-30 10:35:47|1209_0_2_1030_105...|\n",
            "|    164|           2_2407-21|    STOPPED_AT| 41|1257|  38.7086|   1610|-9.296201|  1610_0_2|  1610_0|            SCHEDULED|        2407|7.2222223| 120717|2024-11-30 10:35:33|1610_0_2_1000_102...|\n",
            "|      0|           2_2028-21|    STOPPED_AT| 41|1810|38.748238|   1510|-9.212038|  1510_0_2|  1510_0|            SCHEDULED|   2028'_003|      0.0| 030666|2024-11-30 10:35:15|1510_0_2_1030_105...|\n",
            "+-------+--------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+------------+---------+-------+-------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query.stop()"
      ],
      "metadata": {
        "id": "2NzfbYW5j7_M"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/bronze"
      ],
      "metadata": {
        "id": "W1BCl7BCXo_v"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# watermark is necessary because of the aggregation\n",
        "transformed = stream.withWatermark(\"timestamp\", \"60 seconds\")\n",
        "agg = (transformed\n",
        "       .groupBy(window(transformed.timestamp, \"5 minutes\"), col(\"current_status\"))\n",
        "       .agg(min(transformed.timestamp).alias(\"init_timestamp\"), count(\"*\").alias(\"count\")))\n",
        "\n",
        "def insert_vehicles(df, batch_id): #recebe um df, por default um batch_id\n",
        "  #df2 = df.groupBy(\"window\").pivot(\"current_status\").sum(\"count\")\n",
        "  df.write.format(\"parquet\").mode(\"append\").save(\"/content/bronze/vehicles\") #processo batch -pq o spark stream nao tem um write parque por default\n",
        "\n",
        "# using memory for testing\n",
        "query2 = (agg\n",
        "          .writeStream\n",
        "          .outputMode(\"append\")\n",
        "          .foreachBatch(insert_vehicles) #temos de usar o foreach por ser streaming\n",
        "          .option(\"checkpointLocation\", \"/content/bronze/checkpoint\")\n",
        "          .trigger(processingTime='20 seconds')\n",
        "          .start())"
      ],
      "metadata": {
        "id": "xyDkRdgLUZZt"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.format(\"parquet\").load(\"/content/bronze/vehicles/*\").show(100, False)"
      ],
      "metadata": {
        "id": "d6xqFWyKdujI",
        "outputId": "e7a8d9ba-dc9d-46ea-8f4f-d3e3ff8b6e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+--------------+-------------------+-----+\n",
            "|window                                    |current_status|init_timestamp     |count|\n",
            "+------------------------------------------+--------------+-------------------+-----+\n",
            "|{2024-11-30 10:30:00, 2024-11-30 10:35:00}|IN_TRANSIT_TO |2024-11-30 10:32:45|1495 |\n",
            "|{2024-11-30 10:30:00, 2024-11-30 10:35:00}|INCOMING_AT   |2024-11-30 10:32:49|488  |\n",
            "|{2024-11-30 10:30:00, 2024-11-30 10:35:00}|STOPPED_AT    |2024-11-30 10:32:33|698  |\n",
            "+------------------------------------------+--------------+-------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report\n",
        "- show vehicles by status in 5-min window time\n",
        "- one line per window time"
      ],
      "metadata": {
        "id": "62oGSmx4S8Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pivot_data(df: DataFrame):\n",
        "  result = df.orderBy(\"init_timestamp\").groupBy(\"window\").pivot(\"current_status\").sum(\"count\")\n",
        "  result.show(100, False)\n",
        "\n",
        "df = spark.read.format(\"parquet\").load(\"/content/bronze/vehicles/*\")\n",
        "pivot_data(df)"
      ],
      "metadata": {
        "id": "x38lvoysfKLy",
        "outputId": "04d76056-1c20-4d5d-806a-98f280dfbc5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+-----------+-------------+----------+\n",
            "|window                                    |INCOMING_AT|IN_TRANSIT_TO|STOPPED_AT|\n",
            "+------------------------------------------+-----------+-------------+----------+\n",
            "|{2024-11-30 10:30:00, 2024-11-30 10:35:00}|488        |1495         |698       |\n",
            "+------------------------------------------+-----------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2.stop()"
      ],
      "metadata": {
        "id": "pyDwzbdmO29f"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ETfknUmUeZg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}